<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Uddeshya  Upadhyay


</title>
<meta name="description" content="Building cool stuff.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Uddeshya</span>   Upadhyay
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Uddeshya</span>  Upadhyay
    </h1>
     <p class="desc">Building cool stuff.</p>
  </header>

  <article>
    
    <div class="profile col-3 float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg">
      
      
        <div class="address">
          <strong><small> Tübingen ⇄ Mumbai </small></strong> <p><small>uddeshya.upa@gmail.com</small></p> <small></small><p><a href="https://scholar.google.com/citations?user=Zgk0Z6kAAAAJ&amp;hl=en">Google Scholar</a></p> <p><a href="https://twitter.com/uddupa">Twitter</a></p> <p><a href="https://github.com/udion/">Github</a></p>

        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I am a first-year Ph.D. student at <a href="https://imprs.is.mpg.de/"><strong>IMPRS-IS Program, Tübingen</strong></a>, where I am part of <a href="https://eml-unitue.de/"><strong>EML</strong></a> and <a href="http://midaslab.org/"><strong>MIDAS</strong></a> group, and I work closely with <a href="https://eml-unitue.de/people/zeynep-akata"><strong>Prof. Zeynep Akata</strong></a> and <a href="https://www.medizin.uni-tuebingen.de/de/das-klinikum/mitarbeiter/profil/1479"><strong>Prof. Sergios Gatidis</strong></a>.
I am fascinated by interdisciplinary R&amp;D happening at the intersection of 
Computer Vision, Machine Learning, Biomedical and Healthcare Informatics.
These days I am exploring Bayesian Deep Learning, Uncertainty Estimation, Generative models, and Explainable AI (XAI).</p>

<p>Earlier, I was an undergrad at Computer Science and Engineering@IIT-Bombay.</p>

<p>BTW, <a href="https://www.youtube.com/watch?v=5qap5aO4i9A"><strong>here’s</strong></a> a cool lofi track that I find helpful while working.
<br>
<a href="https://www.youtube.com/watch?v=obCjODeoLVw"><strong>Here’s</strong></a> a video of Prof. R. Feynman talking about Mathematicians and Physicists. <br>
I believe something similar can be said for Researchers and Engineers.</p>

    </div>

    
      <div class="news">
  <h2>Updates</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Jun 15, 2021</th>
          <td>
            
              Our work on Uncertainty-guided Progressive GANs is accepted at MICCAI-21! <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 1, 2021</th>
          <td>
            
              Started my PhD in Tuebingen! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Selected Publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    <img class="img-fluid z-depth-2 rounded" width="1000" src="../assets/img/miccai21.png">
    
    <abbr class="badge">MICCAI 2021</abbr>
    
  
  </div>

  <div id="uu_uncerguidedi2i" class="col-sm-8">
    
      <div class="title">Uncertainty-Guided Progressive GANs for Medical Image Translation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Uddeshya, Upadhyay,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yanbei, Chen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tobias, Hepp,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sergios, Gatidis,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zeynep, Akata
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>MICCAI-International Conference on Medical Image Computing and Computer Assisted Intervention</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://arxiv.org/pdf/2106.15542.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://arxiv.org/pdf/2106.15542.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
    Image-to-image translation plays a vital role in tackling various medical imaging tasks such as attenuation correction, motion correction, undersampled reconstruction, and denoising. Generative adversarial
    networks have been shown to achieve the state-of-the-art in generating
    high fidelity images for these tasks. However, the state-of-the-art GANbased frameworks do not estimate the uncertainty in the predictions
    made by the network that is essential for making informed medical decisions and subsequent revision by medical experts and has recently been
    shown to improve the performance and interpretability of the model. In
    this work, we propose an uncertainty-guided progressive learning scheme
    for image-to-image translation. By incorporating aleatoric uncertainty as
    attention maps for GANs trained in a progressive manner, we generate
    images of increasing fidelity progressively. We demonstrate the efficacy
    of our model on three challenging medical image translation tasks, including PET to CT translation, undersampled MRI reconstruction, and
    MRI motion artefact correction. Our model generalizes well in three different tasks and improves performance over state of the art under fullsupervision and weak-supervision with limited data. Code is released
    here: https://github.com/ExplainableML/UncerGuidedI2I
  </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    <img class="img-fluid z-depth-2 rounded" width="1000" src="../assets/img/miccai19.png">
    
    <abbr class="badge">MICCAI 2019</abbr>
    
  
  </div>

  <div id="uu_qegan" class="col-sm-8">
    
      <div class="title">A Mixed-Supervision Multilevel GAN Framework for Image Quality Enhancement</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Uddeshya, Upadhyay,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Suyash, Awate
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>MICCAI-International Conference on Medical Image Computing and Computer Assisted Intervention</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://doi.org/10.1007/978-3-030-32254-0_62" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/papers/MLQE.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep neural networks for image quality enhancement typically need large quantities of highly-curated training data comprising pairs of low-quality images and their corresponding high-quality images. While high-quality image acquisition is typically expensive and time-consuming, medium-quality images are faster to acquire, at lower equipment costs, and available in larger quantities. Thus, we propose a novel generative adversarial network (GAN) that can leverage training data at multiple levels of quality (e.g., high and medium quality) to improve performance while limiting costs of data curation. We apply our mixed-supervision GAN to (i) super-resolve histopathology images and (ii) enhance laparoscopy images by combining super-resolution and surgical smoke removal. Results on large clinical and pre-clinical datasets show the benefits of our mixed-supervision GAN over the state of the art.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    <img class="img-fluid z-depth-2 rounded" width="1000" src="../assets/img/isbi19.png">
    
    <abbr class="badge">ISBI 2019</abbr>
    
  
  </div>

  <div id="uu_rsrgan" class="col-sm-8">
    
      <div class="title">Robust Super-Resolution GAN, with Manifold-Based and Perception Loss</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Uddeshya, Upadhyay,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Suyash, Awate
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE International Symposium on Biomedical Imaging (ISBI)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/abstract/document/8759375" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/papers/rsrgan.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Super-resolution using deep neural networks typically relies on highly curated training sets that are often unavailable in clinical deployment scenarios. Using loss functions that assume Gaussian-distributed residuals makes the learning sensitive to corruptions in clinical training sets. We propose novel loss functions that are robust to corruptions in training sets by modeling heavy-tailed non-Gaussian distributions on the residuals. We propose a loss based on an autoencoder-based manifold-distance between the super-resolved and high-resolution images, to reproduce realistic textural content in super-resolved images. We propose to learn to super-resolve images to match human perceptions of structure, luminance, and contrast. Results on a large clinical dataset shows the advantages of each of our contributions, where our framework improves over the state of the art.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%75%64%64%65%73%68%79%61.%75%70%61@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=Zgk0Z6kAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/udion" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/uddeshya-upa" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/uddupa" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>










      </div>
      <div class="contact-note">Email is the best way to reach you.
</div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2021 Uddeshya  Upadhyay.
    
    
    
    Last updated: July 10, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
